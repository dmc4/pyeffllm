{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "650703e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from coop import AsyncHandler, AsyncSeqLikeHandler, async_\n",
    "from eff import Handler, Operation, coroutine_decorator\n",
    "from llm import (\n",
    "\tAsyncOneRoundChatHandler,\n",
    "\tAsyncReplayLLMHandler,\n",
    "\tLLMHandler,\n",
    "\tOneRoundChatHandler,\n",
    "\tReplayLLMHandler,\n",
    "\tTraceLLMHandler,\n",
    "\tcomplete,\n",
    "\tparse,\n",
    ")\n",
    "from util import Timer, awaitable_args_decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afe6e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 注意这个！！！\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f451fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "#BASE_URL = os.getenv(\"BASE_URL\")\n",
    "#API_KEY = os.getenv(\"API_KEY\")\n",
    "\n",
    "#TODO lazy way!! will change!!!\n",
    "BASE_URL='https://api.openai-proxy.org/v1'\n",
    "API_KEY=''\n",
    "\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "TEMPERATURE = 1.0\n",
    "MAX_TOKENS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c84d6b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TOPICS = \"Give a list of topics in the research area: {area}.\"\n",
    "PROMPT_DESCRIPTION = \"Give a short description about the research topic: {topic}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bfc100d",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_topics = Operation()\n",
    "get_description = Operation()\n",
    "log = Operation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d78c6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResearchArea(BaseModel):\n",
    "\ttopics: list[str]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf2db02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResearchTopicsHandler(Handler):\n",
    "\t\"\"\"\n",
    "\thandles: get_topics, get_description, log\n",
    "\n",
    "\tforward: parse, complete\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(self):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.register(get_topics, self.get_topics)\n",
    "\t\tself.register(get_description, self.get_description)\n",
    "\t\tself.register(log, print)\n",
    "\n",
    "\tdef get_topics(self, area):\n",
    "\t\tresponse = parse(\"topics\", PROMPT_TOPICS.format(area=area), ResearchArea)\n",
    "\t\treturn response.choices[0].message.parsed.topics\n",
    "\n",
    "\tdef get_description(self, topic):\n",
    "\t\tresponse = complete(f\"desc_{topic}\", PROMPT_DESCRIPTION.format(topic=topic))\n",
    "\t\treturn response.choices[0].message.content\n",
    "\n",
    "\n",
    "class AsyncResearchTopicsHandler(Handler):\n",
    "\t\"\"\"\n",
    "\thandles: get_topics, get_description, log\n",
    "\n",
    "\tforward: parse, complete, async, await\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(self):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.register(get_topics, self.get_topics)\n",
    "\t\tself.register(get_description, self.get_description)\n",
    "\t\tself.register(log, self.log)\n",
    "\n",
    "\tdef get_topics(self, area):\n",
    "\t\t@awaitable_args_decorator\n",
    "\t\t@coroutine_decorator\n",
    "\t\tasync def aux(area):\n",
    "\t\t\tresponse = await parse(\n",
    "\t\t\t\t\"topics\", PROMPT_TOPICS.format(area=area), ResearchArea\n",
    "\t\t\t)\n",
    "\t\t\treturn response.choices[0].message.parsed.topics\n",
    "\n",
    "\t\treturn AsyncHandler.wrap_future_object(async_(aux(area)), \"__iter__\")\n",
    "\n",
    "\tdef get_description(self, topic):\n",
    "\t\t@awaitable_args_decorator\n",
    "\t\t@coroutine_decorator\n",
    "\t\tasync def aux(topic):\n",
    "\t\t\tresponse = await complete(\n",
    "\t\t\t\tf\"desc_{topic}\", PROMPT_DESCRIPTION.format(topic=topic)\n",
    "\t\t\t)\n",
    "\t\t\treturn response.choices[0].message.content\n",
    "\n",
    "\t\treturn async_(aux(topic))\n",
    "\n",
    "\tdef log(self, msg):\n",
    "\t\t@awaitable_args_decorator\n",
    "\t\t@coroutine_decorator\n",
    "\t\tasync def aux(msg):\n",
    "\t\t\treturn msg\n",
    "\n",
    "\t\treturn async_(aux(msg), print)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5ff0687",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\ttopics = get_topics(\"PL techniques for LLM applications\")\n",
    "\tfor topic in topics:\n",
    "\t\tlog(topic)\n",
    "\t\tdescrption = get_description(topic)\n",
    "\t\tlog(descrption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd7c0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Programming Language Design for LLMs\n",
      "Programming Language Design for Large Language Models (LLMs) focuses on creating and optimizing programming languages specifically tailored for interacting with and leveraging the capabilities of LLMs. This research area explores how to design syntax, semantics, and features that facilitate efficient input, manipulation, and output of text generated by LLMs. It emphasizes enhancing usability, readability, and expressiveness for developers, while considering the unique characteristics of LLMs, such as their ability to understand and generate natural language. Additionally, the research investigates how to integrate LLMs into existing languages, developing novel paradigms for code generation, natural language processing, and automated reasoning, ultimately aiming to improve human-computer collaboration in programming tasks.\n",
      "Compiler Techniques for LLM Optimization\n",
      "Compiler Techniques for LLM Optimization is a research area focused on improving the performance and efficiency of Large Language Models (LLMs) through advanced compilation strategies. This includes the development of algorithms and methodologies to optimize model inference, reduce latency, and enhance memory usage. Key techniques may involve model quantization, pruning, operator fusion, and optimizing underlying hardware utilization (such as GPUs and TPUs). The goal is to enable faster, more efficient deployment of LLMs in various applications while maintaining their accuracy and robustness. This research often intersects with fields like machine learning, systems programming, and computer architecture, addressing challenges like scalability and real-time processing demands.\n",
      "Type Systems in LLM Applications\n",
      "The research topic \"Type Systems in LLM Applications\" explores the integration and utilization of type systems within the context of large language models (LLMs). Type systems are formal mechanisms used in programming languages to classify and enforce constraints on data types, helping to prevent errors and improve code reliability. In the domain of LLMs, the study focuses on how type systems can enhance the development, deployment, and reliability of applications using these models. This includes investigating ways to specify and enforce type constraints on inputs and outputs, facilitating better model interpretability, ensuring consistency in generated results, and improving user interaction through better error handling and guidance. Additionally, the research examines the impact of type systems on the overall performance and robustness of LLMs in various applications, such as natural language processing, code generation, and automated reasoning, aiming to bridge the gap between formal programming principles and the more informal nature of language model interactions.\n",
      "Domain-Specific Languages for LLM Interactions\n",
      "Domain-Specific Languages (DSLs) for Large Language Model (LLM) interactions focus on creating tailored programming languages or scripting languages designed to facilitate the interaction between users and LLMs. These DSLs aim to simplify the process of formulating queries, commands, or tasks that can be effectively processed by LLMs, enhancing usability and productivity in specific domains such as healthcare, finance, customer support, or education. By providing a syntax and semantics optimized for particular tasks, DSLs can help users express complex ideas succinctly, enable better error handling and suggestions, and improve the overall efficiency of utilizing LLMs. The research in this area may cover the design, implementation, and evaluation of such languages, as well as case studies demonstrating their benefits in real-world applications.\n",
      "Static Analysis for LLM Code Generation\n",
      "Static Analysis for LLM Code Generation focuses on developing techniques and tools to evaluate and analyze code generated by Large Language Models (LLMs) without executing it. This area of research aims to ensure the reliability, security, and quality of code produced by LLMs, which can sometimes generate incorrect or unsafe code snippets. By applying static analysis methods, researchers can identify potential issues such as syntax errors, security vulnerabilities, and adherence to coding standards in the generated code. The goal is to improve the robustness and trustworthiness of LLMs in software development, ultimately enhancing their utility in practical applications.\n",
      "Dynamic Analysis in LLM frameworks\n",
      "Dynamic Analysis in Large Language Model (LLM) frameworks involves the examination of how these models operate and evolve during runtime, as opposed to static analysis, which focuses on their architecture and parameters without execution. This research topic addresses various aspects, such as monitoring LLM behavior in real-time, understanding model decision-making processes, evaluating their performance under different conditions, and assessing the impact of dynamic inputs on their outputs. It also seeks to identify vulnerabilities, biases, and potential improvements in LLMs by observing interactions and adaptability to diverse contexts. By leveraging dynamic analysis techniques, researchers aim to enhance the robustness, reliability, and ethical deployment of LLMs across applications.\n",
      "Error Handling and Debugging Techniques in LLMs\n",
      "Error Handling and Debugging Techniques in LLMs (Large Language Models) focuses on the methodologies and strategies to identify, understand, and resolve errors or unintended outputs generated by these AI models. Given the complexity and scale of LLMs, traditional debugging techniques may not be directly applicable, necessitating the development of specialized approaches.\n",
      "\n",
      "This research encompasses several key areas:\n",
      "\n",
      "1. **Error Classification**: Identifying different types of errors, such as factual inaccuracies, logical inconsistencies, or inappropriate responses.\n",
      "\n",
      "2. **Debugging Tools**: Developing tools and frameworks that help researchers and developers analyze model behavior, track down issues in the generation processes, and understand the causal factors leading to errors.\n",
      "\n",
      "3. **Explainability**: Investigating ways to make LLM outputs more interpretable, allowing users to understand why a model generated a particular response, which can aid in both debugging and trust in AI systems.\n",
      "\n",
      "4. **Performance Evaluation**: Creating metrics and benchmarks to assess the robustness and reliability of LLMs, examining how well they handle ambiguous, misleading, or adversarial input.\n",
      "\n",
      "5. **Mitigation Strategies**: Exploring techniques to reduce error rates, such as improved training methodologies, fine-tuning, and incorporating feedback loops that allow models to learn from their mistakes.\n",
      "\n",
      "Overall, the research in this area aims to enhance the reliability and effectiveness of LLMs, making them safer and more trustworthy tools for a variety of applications.\n",
      "Runtime Environment for LLM Execution\n",
      "The research topic \"Runtime Environment for LLM Execution\" focuses on developing and optimizing environments in which large language models (LLMs) can be effectively executed. This encompasses the design of software and hardware interfaces that enable efficient model loading, inference, and resource management. Key considerations include performance optimization, scalability, and the integration of various runtime components such as memory management, task scheduling, and parallel processing. The goal is to create a robust and flexible runtime environment that supports both the unique requirements of LLMs and their deployment in various application scenarios, such as cloud-based services, edge computing, and real-time inference applications. This field also involves investigating efficiency improvements, ensuring reliability, and exploring the integration of LLMs with other AI systems and technologies.\n",
      "Integration of LLMs with traditional PLs\n",
      "The integration of Large Language Models (LLMs) with traditional programming languages (PLs) explores the synergies between advanced AI-driven natural language processing capabilities and conventional coding practices. This research area focuses on enhancing software development workflows by leveraging LLMs to assist in code generation, debugging, documentation, and natural language queries about codebases. It investigates how LLMs can be effectively trained to understand and generate code in traditional programming languages, enabling more intuitive programming experiences, fostering collaboration between human developers and AI, and potentially transforming software engineering practices. Furthermore, it addresses challenges related to correctness, security, and interpretability of AI-generated code, aiming to create tools that augment programmer productivity while maintaining reliability and trustworthiness in the software development process.\n",
      "Performance Optimization of LLMs using PL Techniques\n",
      "The research topic \"Performance Optimization of LLMs using PL Techniques\" explores the intersection of Large Language Models (LLMs) and programming language (PL) techniques to enhance the efficiency and effectiveness of LLMs. This involves investigating methods such as model pruning, quantization, and distillation, which are traditional PL optimization strategies, to improve the speed, memory usage, and deployment of LLMs. The goal is to reduce computational overhead while maintaining or enhancing model accuracy and performance in various applications, such as natural language processing and machine learning deployments. Additionally, the research may delve into the use of advanced tools and frameworks from PL to facilitate the integration of optimization techniques into LLM training and inference workflows.\n",
      "Formal Verification of LLM Outputs\n",
      "The research topic \"Formal Verification of LLM Outputs\" focuses on developing rigorous methods to ensure that the outputs generated by Large Language Models (LLMs) are correct, trustworthy, and aligned with specific criteria or constraints. This area of study seeks to apply formal methods—mathematical techniques used to prove the correctness of systems—to verify the accuracy, consistency, and reliability of LLM outputs. Key challenges include addressing the inherent uncertainty and variability in LLM responses, defining appropriate specifications for correctness, and creating algorithms that can efficiently evaluate the outputs of these complex models. The goal is to enhance the safety and applicability of LLMs in critical domains, such as automated reasoning, legal text processing, and other areas where precise and verifiable information is paramount.\n",
      "Interoperability between LLMs and existing PLs\n",
      "The research topic of interoperability between large language models (LLMs) and existing programming languages (PLs) focuses on exploring how LLMs can effectively integrate and interact with current programming languages to enhance software development processes. This includes understanding how LLMs can understand, generate, and manipulate code written in various programming languages, as well as how they can be utilized to improve code quality, automate routine coding tasks, assist with debugging, and provide advanced documentation and comments. The research aims to address challenges such as ensuring semantic accuracy, maintaining programming language nuances, and developing tools or frameworks that facilitate seamless collaboration between LLMs and human programmers, ultimately leading to more efficient and innovative software engineering practices.\n",
      "Meta-Programming with LLMs\n",
      "Meta-programming with Large Language Models (LLMs) refers to the use of advanced AI technologies, particularly large neural networks trained on vast amounts of programming and natural language data, to generate, manipulate, and analyze code dynamically. This research topic explores how LLMs can assist in various programming tasks, including code generation, code completion, refactoring, documentation, and even the automated generation of program synthesis components. \n",
      "\n",
      "Key areas of investigation often include understanding the capacity of LLMs to infer programming logic, enhance developer productivity, support education in programming, and facilitate the generation of code that adheres to specific constraints or optimizations. Additionally, researchers may delve into the challenges of ensuring code safety, security, and correctness when allowing LLMs to auto-generate or modify code, as well as the implications of these technologies on software engineering practices. Overall, this topic represents a convergence of AI, programming languages, and software development methodologies, with significant potential to revolutionize how programmers interact with code and augment their creative processes.\n",
      "Constraint Checking in LLM Code\n",
      "Constraint Checking in LLM (Large Language Model) Code refers to the process of validating the outputs generated by LLMs, particularly in the context of programming and code generation. This research topic explores methods to ensure that the generated code adheres to specific constraints, such as syntax correctness, semantic validity, security principles, and performance benchmarks. It involves developing techniques to automate the verification process, utilizing tools like static analysis, formal verification, and runtime testing. The goal is to enhance the reliability and safety of code produced by LLMs, addressing challenges like inherent biases in training data, model interpretability, and the potential for generating faulty or vulnerable code. As LLMs become increasingly integrated into software development workflows, constraint checking plays a crucial role in ensuring the quality and trustworthiness of AI-generated code.\n",
      "Tooling for LLM Development and Testing\n",
      "The research topic \"Tooling for LLM Development and Testing\" focuses on creating and enhancing tools and frameworks that facilitate the development, evaluation, and deployment of Large Language Models (LLMs). This includes developing software tools for data preparation, model training, and fine-tuning, as well as testing methodologies to ensure model performance, robustness, and safety. Key areas of interest may involve automation of model evaluation processes, integration of diverse datasets, benchmarking against various metrics, and the implementation of user-friendly interfaces for researchers and developers. The goal is to streamline the LLM lifecycle from inception to production, ensuring models are reliable, ethical, and easy to integrate into real-world applications.\n",
      "sync time: 37.743088499992155\n",
      "Programming Language Design for LLMs\n",
      "Programming Language Design for Large Language Models (LLMs) focuses on creating and optimizing programming languages specifically tailored for interacting with and leveraging the capabilities of LLMs. This research area explores how to design syntax, semantics, and features that facilitate efficient input, manipulation, and output of text generated by LLMs. It emphasizes enhancing usability, readability, and expressiveness for developers, while considering the unique characteristics of LLMs, such as their ability to understand and generate natural language. Additionally, the research investigates how to integrate LLMs into existing languages, developing novel paradigms for code generation, natural language processing, and automated reasoning, ultimately aiming to improve human-computer collaboration in programming tasks.\n",
      "Compiler Techniques for LLM Optimization\n",
      "Compiler Techniques for LLM Optimization is a research area focused on improving the performance and efficiency of Large Language Models (LLMs) through advanced compilation strategies. This includes the development of algorithms and methodologies to optimize model inference, reduce latency, and enhance memory usage. Key techniques may involve model quantization, pruning, operator fusion, and optimizing underlying hardware utilization (such as GPUs and TPUs). The goal is to enable faster, more efficient deployment of LLMs in various applications while maintaining their accuracy and robustness. This research often intersects with fields like machine learning, systems programming, and computer architecture, addressing challenges like scalability and real-time processing demands.\n",
      "Type Systems in LLM Applications\n",
      "The research topic \"Type Systems in LLM Applications\" explores the integration and utilization of type systems within the context of large language models (LLMs). Type systems are formal mechanisms used in programming languages to classify and enforce constraints on data types, helping to prevent errors and improve code reliability. In the domain of LLMs, the study focuses on how type systems can enhance the development, deployment, and reliability of applications using these models. This includes investigating ways to specify and enforce type constraints on inputs and outputs, facilitating better model interpretability, ensuring consistency in generated results, and improving user interaction through better error handling and guidance. Additionally, the research examines the impact of type systems on the overall performance and robustness of LLMs in various applications, such as natural language processing, code generation, and automated reasoning, aiming to bridge the gap between formal programming principles and the more informal nature of language model interactions.\n",
      "Domain-Specific Languages for LLM Interactions\n",
      "Domain-Specific Languages (DSLs) for Large Language Model (LLM) interactions focus on creating tailored programming languages or scripting languages designed to facilitate the interaction between users and LLMs. These DSLs aim to simplify the process of formulating queries, commands, or tasks that can be effectively processed by LLMs, enhancing usability and productivity in specific domains such as healthcare, finance, customer support, or education. By providing a syntax and semantics optimized for particular tasks, DSLs can help users express complex ideas succinctly, enable better error handling and suggestions, and improve the overall efficiency of utilizing LLMs. The research in this area may cover the design, implementation, and evaluation of such languages, as well as case studies demonstrating their benefits in real-world applications.\n",
      "Static Analysis for LLM Code Generation\n",
      "Static Analysis for LLM Code Generation focuses on developing techniques and tools to evaluate and analyze code generated by Large Language Models (LLMs) without executing it. This area of research aims to ensure the reliability, security, and quality of code produced by LLMs, which can sometimes generate incorrect or unsafe code snippets. By applying static analysis methods, researchers can identify potential issues such as syntax errors, security vulnerabilities, and adherence to coding standards in the generated code. The goal is to improve the robustness and trustworthiness of LLMs in software development, ultimately enhancing their utility in practical applications.\n",
      "Dynamic Analysis in LLM frameworks\n",
      "Dynamic Analysis in Large Language Model (LLM) frameworks involves the examination of how these models operate and evolve during runtime, as opposed to static analysis, which focuses on their architecture and parameters without execution. This research topic addresses various aspects, such as monitoring LLM behavior in real-time, understanding model decision-making processes, evaluating their performance under different conditions, and assessing the impact of dynamic inputs on their outputs. It also seeks to identify vulnerabilities, biases, and potential improvements in LLMs by observing interactions and adaptability to diverse contexts. By leveraging dynamic analysis techniques, researchers aim to enhance the robustness, reliability, and ethical deployment of LLMs across applications.\n",
      "Error Handling and Debugging Techniques in LLMs\n",
      "Error Handling and Debugging Techniques in LLMs (Large Language Models) focuses on the methodologies and strategies to identify, understand, and resolve errors or unintended outputs generated by these AI models. Given the complexity and scale of LLMs, traditional debugging techniques may not be directly applicable, necessitating the development of specialized approaches.\n",
      "\n",
      "This research encompasses several key areas:\n",
      "\n",
      "1. **Error Classification**: Identifying different types of errors, such as factual inaccuracies, logical inconsistencies, or inappropriate responses.\n",
      "\n",
      "2. **Debugging Tools**: Developing tools and frameworks that help researchers and developers analyze model behavior, track down issues in the generation processes, and understand the causal factors leading to errors.\n",
      "\n",
      "3. **Explainability**: Investigating ways to make LLM outputs more interpretable, allowing users to understand why a model generated a particular response, which can aid in both debugging and trust in AI systems.\n",
      "\n",
      "4. **Performance Evaluation**: Creating metrics and benchmarks to assess the robustness and reliability of LLMs, examining how well they handle ambiguous, misleading, or adversarial input.\n",
      "\n",
      "5. **Mitigation Strategies**: Exploring techniques to reduce error rates, such as improved training methodologies, fine-tuning, and incorporating feedback loops that allow models to learn from their mistakes.\n",
      "\n",
      "Overall, the research in this area aims to enhance the reliability and effectiveness of LLMs, making them safer and more trustworthy tools for a variety of applications.\n",
      "Runtime Environment for LLM Execution\n",
      "The research topic \"Runtime Environment for LLM Execution\" focuses on developing and optimizing environments in which large language models (LLMs) can be effectively executed. This encompasses the design of software and hardware interfaces that enable efficient model loading, inference, and resource management. Key considerations include performance optimization, scalability, and the integration of various runtime components such as memory management, task scheduling, and parallel processing. The goal is to create a robust and flexible runtime environment that supports both the unique requirements of LLMs and their deployment in various application scenarios, such as cloud-based services, edge computing, and real-time inference applications. This field also involves investigating efficiency improvements, ensuring reliability, and exploring the integration of LLMs with other AI systems and technologies.\n",
      "Integration of LLMs with traditional PLs\n",
      "The integration of Large Language Models (LLMs) with traditional programming languages (PLs) explores the synergies between advanced AI-driven natural language processing capabilities and conventional coding practices. This research area focuses on enhancing software development workflows by leveraging LLMs to assist in code generation, debugging, documentation, and natural language queries about codebases. It investigates how LLMs can be effectively trained to understand and generate code in traditional programming languages, enabling more intuitive programming experiences, fostering collaboration between human developers and AI, and potentially transforming software engineering practices. Furthermore, it addresses challenges related to correctness, security, and interpretability of AI-generated code, aiming to create tools that augment programmer productivity while maintaining reliability and trustworthiness in the software development process.\n",
      "Performance Optimization of LLMs using PL Techniques\n",
      "The research topic \"Performance Optimization of LLMs using PL Techniques\" explores the intersection of Large Language Models (LLMs) and programming language (PL) techniques to enhance the efficiency and effectiveness of LLMs. This involves investigating methods such as model pruning, quantization, and distillation, which are traditional PL optimization strategies, to improve the speed, memory usage, and deployment of LLMs. The goal is to reduce computational overhead while maintaining or enhancing model accuracy and performance in various applications, such as natural language processing and machine learning deployments. Additionally, the research may delve into the use of advanced tools and frameworks from PL to facilitate the integration of optimization techniques into LLM training and inference workflows.\n",
      "Formal Verification of LLM Outputs\n",
      "The research topic \"Formal Verification of LLM Outputs\" focuses on developing rigorous methods to ensure that the outputs generated by Large Language Models (LLMs) are correct, trustworthy, and aligned with specific criteria or constraints. This area of study seeks to apply formal methods—mathematical techniques used to prove the correctness of systems—to verify the accuracy, consistency, and reliability of LLM outputs. Key challenges include addressing the inherent uncertainty and variability in LLM responses, defining appropriate specifications for correctness, and creating algorithms that can efficiently evaluate the outputs of these complex models. The goal is to enhance the safety and applicability of LLMs in critical domains, such as automated reasoning, legal text processing, and other areas where precise and verifiable information is paramount.\n",
      "Interoperability between LLMs and existing PLs\n",
      "The research topic of interoperability between large language models (LLMs) and existing programming languages (PLs) focuses on exploring how LLMs can effectively integrate and interact with current programming languages to enhance software development processes. This includes understanding how LLMs can understand, generate, and manipulate code written in various programming languages, as well as how they can be utilized to improve code quality, automate routine coding tasks, assist with debugging, and provide advanced documentation and comments. The research aims to address challenges such as ensuring semantic accuracy, maintaining programming language nuances, and developing tools or frameworks that facilitate seamless collaboration between LLMs and human programmers, ultimately leading to more efficient and innovative software engineering practices.\n",
      "Meta-Programming with LLMs\n",
      "Meta-programming with Large Language Models (LLMs) refers to the use of advanced AI technologies, particularly large neural networks trained on vast amounts of programming and natural language data, to generate, manipulate, and analyze code dynamically. This research topic explores how LLMs can assist in various programming tasks, including code generation, code completion, refactoring, documentation, and even the automated generation of program synthesis components. \n",
      "\n",
      "Key areas of investigation often include understanding the capacity of LLMs to infer programming logic, enhance developer productivity, support education in programming, and facilitate the generation of code that adheres to specific constraints or optimizations. Additionally, researchers may delve into the challenges of ensuring code safety, security, and correctness when allowing LLMs to auto-generate or modify code, as well as the implications of these technologies on software engineering practices. Overall, this topic represents a convergence of AI, programming languages, and software development methodologies, with significant potential to revolutionize how programmers interact with code and augment their creative processes.\n",
      "Constraint Checking in LLM Code\n",
      "Constraint Checking in LLM (Large Language Model) Code refers to the process of validating the outputs generated by LLMs, particularly in the context of programming and code generation. This research topic explores methods to ensure that the generated code adheres to specific constraints, such as syntax correctness, semantic validity, security principles, and performance benchmarks. It involves developing techniques to automate the verification process, utilizing tools like static analysis, formal verification, and runtime testing. The goal is to enhance the reliability and safety of code produced by LLMs, addressing challenges like inherent biases in training data, model interpretability, and the potential for generating faulty or vulnerable code. As LLMs become increasingly integrated into software development workflows, constraint checking plays a crucial role in ensuring the quality and trustworthiness of AI-generated code.\n",
      "Tooling for LLM Development and Testing\n",
      "The research topic \"Tooling for LLM Development and Testing\" focuses on creating and enhancing tools and frameworks that facilitate the development, evaluation, and deployment of Large Language Models (LLMs). This includes developing software tools for data preparation, model training, and fine-tuning, as well as testing methodologies to ensure model performance, robustness, and safety. Key areas of interest may involve automation of model evaluation processes, integration of diverse datasets, benchmarking against various metrics, and the implementation of user-friendly interfaces for researchers and developers. The goal is to streamline the LLM lifecycle from inception to production, ensuring models are reliable, ethical, and easy to integrate into real-world applications.\n",
      "async time: 6.114000000001397\n",
      "speedup: 6.173223503432046x\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\tif not os.path.exists(\"research_topics.trace\"):\n",
    "\t\twith (\n",
    "\t\t\tLLMHandler(base_url=BASE_URL, api_key=API_KEY),\n",
    "\t\t\tTraceLLMHandler() as trace,\n",
    "\t\t\tOneRoundChatHandler(\n",
    "\t\t\t\tmodel=MODEL,\n",
    "\t\t\t\ttemperature=TEMPERATURE,\n",
    "\t\t\t\tmax_tokens=MAX_TOKENS,\n",
    "\t\t\t),\n",
    "\t\t\tResearchTopicsHandler(),\n",
    "\t\t):\n",
    "\t\t\tmain()\n",
    "\t\twith open(\"research_topics.trace\", \"wb\") as f:\n",
    "\t\t\tpickle.dump(trace, f)\n",
    "\n",
    "\twith open(\"research_topics.trace\", \"rb\") as f:\n",
    "\t\ttrace = pickle.load(f)\n",
    "\twith Timer() as t_sync:\n",
    "\t\twith ReplayLLMHandler(trace), OneRoundChatHandler(), ResearchTopicsHandler():\n",
    "\t\t\tmain()\n",
    "\tprint(f\"sync time: {t_sync.time}\")\n",
    "\n",
    "\twith open(\"research_topics.trace\", \"rb\") as f:\n",
    "\t\ttrace = pickle.load(f)\n",
    "\twith Timer() as t_async:\n",
    "\t\twith (\n",
    "\t\t\tAsyncHandler(),\n",
    "\t\t\tAsyncReplayLLMHandler(trace),\n",
    "\t\t\tAsyncOneRoundChatHandler(),\n",
    "\t\t\tAsyncSeqLikeHandler(),\n",
    "\t\t\tAsyncResearchTopicsHandler(),\n",
    "\t\t):\n",
    "\t\t\tmain()\n",
    "\tprint(f\"async time: {t_async.time}\")\n",
    "\n",
    "\tprint(f\"speedup: {t_sync.time / t_async.time}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0092ce7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
